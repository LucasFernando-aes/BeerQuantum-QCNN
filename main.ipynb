{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# QCNNs para reconhecimento de Reciclagem - latas, garrafas e caixas.\n",
    "## Grupo: L2D2\n",
    "## Débora Dauma, Lucas Alvarenga e Marina Fernandes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### leitura de bibliotecas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from math import ceil\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inicialização de Parâmetros "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#quantum parameters\n",
    "n_qubits = 4\n",
    "q_depth = 6\n",
    "q_delta = 0.001\n",
    "\n",
    "#classical: training parameters.\n",
    "dataset_path = 'raw_dataset/recicle_data_shuffle.npz'\n",
    "validation_split = 0.2\n",
    "batch_size=4\n",
    "epochs = 3\n",
    "learning_rate = 0.001\n",
    "gamma = 0.1\n",
    "\n",
    "#random generator\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "## devices\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Leitura dos dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class RecycleDatased(VisionDataset):\n",
    "    def __init__(self, root, dataset, transform=None, target_transform=None, image=True):\n",
    "        super(RecycleDatased, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        self.transform_image = image\n",
    "        self.x = dataset['observations']\n",
    "        self.y = dataset['labels']\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.transform_image:\n",
    "            x, y = Image.fromarray(self.x[i]), self.y[i]\n",
    "        else:\n",
    "            x, y = self.x[i], self.y[i]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            y = self.target_transform(y)\n",
    "\n",
    "        return (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# read data\n",
    "data = np.load('raw_dataset/recycle_data_shuffled.npz')\n",
    "x, y = data['x_train'], data['y_train']\n",
    "#y = torch.from_numpy(y[:, 0]).long()\n",
    "\n",
    "idxs = np.concatenate([np.argwhere(y == 2)[:, 0], np.argwhere(y == 3)[:, 0]])\n",
    "x = x[idxs, ...]\n",
    "y = torch.from_numpy(y[idxs][:, 0]).long()\n",
    "\n",
    "# shuffle the data\n",
    "idxs = np.random.randint(0, x.shape[0], x.shape[0])\n",
    "x = x[idxs, ...]\n",
    "y = y[idxs]\n",
    "\n",
    "# split data\n",
    "num_train = ceil((1-validation_split)*x.shape[0])\n",
    "x_train = x[:num_train]\n",
    "y_train = y[:num_train]\n",
    "x_test = x[num_train:]\n",
    "y_test = y[num_train:]\n",
    "\n",
    "print(x_train.shape, x_test.shape, num_train)\n",
    "\n",
    "# transformations resnet18 imagem (224,224) -> (512)\n",
    "transforms = {\"train\": T.Compose([T.Resize(256), T.RandomCrop(224), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "            \"test\": T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "target_transform = lambda x: 0 if x == 2 else 1\n",
    "\n",
    "# datasets\n",
    "train_dataset = RecycleDatased('raw_dataset', {\"observations\": x_train, \"labels\": y_train}, transform=transforms['train'], target_transform=target_transform)\n",
    "test_dataset = RecycleDatased('raw_dataset', {\"observations\": x_test, \"labels\": y_test}, transform=transforms['test'], target_transform=target_transform)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size*10, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size*10, shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2944, 128, 128, 3) (736, 128, 128, 3) 2944\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criação do Modelo CNN classico"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = resnet18(pretrained='true')\n",
    "num_features = model.fc.out_features\n",
    "model.fc = nn.Identity()\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtendo os vetores de características"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train, test = [], []\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        train.append(model(x).cpu())\n",
    "\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "        test.append(model(x).cpu())\n",
    "\n",
    "train = torch.cat(train)\n",
    "test = torch.cat(test)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# datasets\n",
    "train_features = RecycleDatased('raw_dataset', {\"observations\": train, \"labels\": y_train}, target_transform=target_transform, image=False)\n",
    "test_features = RecycleDatased('raw_dataset', {\"observations\": test, \"labels\": y_test}, target_transform=target_transform, image=False)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_features, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_features, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2944, 512]) torch.Size([736, 512])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criação do Módulo Quântico -> Pennylane + Torch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    for idx in range(n_qubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    for idx, element in enumerate(q_input_features):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "    # Sequence of trainable variational layers\n",
    "    for k in range(q_depth):\n",
    "        for i in range(0, n_qubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "        \n",
    "        for i in range(1, n_qubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "        for idx, element in enumerate(q_weights[k]):\n",
    "            qml.RY(element, wires=idx)\n",
    "\n",
    "    # Expectation values in the Z basis\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class DressedQuantumNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fase de Treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "q_module = DressedQuantumNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(q_module.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=gamma)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "accuracies, errors = [], []\n",
    "for e in range(epochs):\n",
    "    running_count = 0.\n",
    "    running_error = 0.\n",
    "    count = 0\n",
    "\n",
    "    q_module.train()\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, (x, y) in enumerate(train_loader):        \n",
    "            outputs = q_module(x)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            count += x.shape[0]\n",
    "            running_error += loss\n",
    "            running_count += preds.eq(y).sum()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(1)\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"[Epoca {e+1}] Treino -> Acuracia: {running_count/count}; Erro {running_error/count} \")\n",
    "\n",
    "    running_count = 0.\n",
    "    running_error = 0.\n",
    "    count = 0\n",
    "    \n",
    "    q_module.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(test_loader)) as pbar:\n",
    "            for i, (x, y) in enumerate(test_loader):\n",
    "                outputs = q_module(x)\n",
    "\n",
    "                loss = criterion(outputs, y)\n",
    "                \n",
    "                count += x.shape[0]\n",
    "                running_error += loss\n",
    "                running_count += (torch.max(outputs, 1)[1]).eq(y).sum()\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "    print(f\"[Epoca {e+1}] Teste -> Acuracia: {running_count/count}; Erro {running_error/count} \")\n",
    "    accuracies.append(running_count/count)\n",
    "    errors.append(running_error/count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 736/736 [01:22<00:00,  8.92it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoca 1] Treino -> Acuracia: 0.9228940010070801; Erro 0.05989013612270355 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 184/184 [00:11<00:00, 16.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoca 1] Teste -> Acuracia: 0.94972825050354; Erro 0.038512151688337326 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 736/736 [01:11<00:00, 10.29it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoca 2] Treino -> Acuracia: 0.942255437374115; Erro 0.04160948842763901 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 184/184 [00:10<00:00, 17.10it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoca 2] Teste -> Acuracia: 0.948369562625885; Erro 0.03737277165055275 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 736/736 [01:11<00:00, 10.34it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoca 3] Treino -> Acuracia: 0.94972825050354; Erro 0.03480280563235283 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 184/184 [00:10<00:00, 17.17it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoca 3] Teste -> Acuracia: 0.938858687877655; Erro 0.04524167627096176 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "interpreter": {
   "hash": "c7b3fb1444305e41bd5c86ff9d8bf61df2144911d170c7a5528a56564d3e8f75"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}